{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "560c3edc",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32f590e-1a6b-49fe-b61b-8460c42fbc78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T16:03:59.589070Z",
     "iopub.status.busy": "2023-01-10T16:03:59.588777Z",
     "iopub.status.idle": "2023-01-10T16:03:59.608821Z",
     "shell.execute_reply": "2023-01-10T16:03:59.606955Z",
     "shell.execute_reply.started": "2023-01-10T16:03:59.589046Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import statistics\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "from itertools import compress\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Audio\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import cm\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import (\n",
    "    f1_score, average_precision_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RepeatedStratifiedKFold,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import json\n",
    "from federated_eval_helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b8450a-d36c-49a8-812d-495af1081b95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T16:01:43.296433Z",
     "iopub.status.busy": "2023-01-10T16:01:43.296352Z",
     "iopub.status.idle": "2023-01-10T16:01:43.298291Z",
     "shell.execute_reply": "2023-01-10T16:01:43.297886Z",
     "shell.execute_reply.started": "2023-01-10T16:01:43.296424Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "REPS = 10\n",
    "CV_NUMBER = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88441fd-d7cf-44d5-877a-f9af96e4c1b1",
   "metadata": {},
   "source": [
    "# import treated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b2f3f87-8aa0-4798-aaee-34ffc6378dd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T16:01:43.298808Z",
     "iopub.status.busy": "2023-01-10T16:01:43.298743Z",
     "iopub.status.idle": "2023-01-10T16:01:44.105984Z",
     "shell.execute_reply": "2023-01-10T16:01:44.105093Z",
     "shell.execute_reply.started": "2023-01-10T16:01:43.298800Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Collect all the font names available to matplotlib\n",
    "font_names = [f.name for f in fm.fontManager.ttflist]\n",
    "#print(font_names)\n",
    "# Edit the font, font size, and axes width\n",
    "mpl.rcParams[\"font.family\"] = \"Avenir\"\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "plt.rcParams[\"axes.linewidth\"] = 2\n",
    "# Generate 2 colors from the 'tab10' colormap\n",
    "colors = cm.get_cmap(\"tab10\", 2)\n",
    "\n",
    "sound_file = \"https://www.soundjay.com/buttons/button-09a.wav\"  # https://www.soundjay.com/buttons/sounds/button-1.mp3\n",
    "alarm = Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b786714e-0e35-49b7-b70c-916c1165f60b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T16:01:44.108951Z",
     "iopub.status.busy": "2023-01-10T16:01:44.108242Z",
     "iopub.status.idle": "2023-01-10T16:01:44.300166Z",
     "shell.execute_reply": "2023-01-10T16:01:44.299774Z",
     "shell.execute_reply.started": "2023-01-10T16:01:44.108918Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "silo_imputed = []\n",
    "for idx, file in enumerate(glob.glob(\"/Users/joaoalmeida/Desktop/tese_local/Obscare Giovana/imputed/silo*.csv\")):\n",
    "    silo_imputed.append(pd.read_csv(file, index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021b5b92-6b13-41a9-9af8-c1b1e6855094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T16:01:44.300796Z",
     "iopub.status.busy": "2023-01-10T16:01:44.300720Z",
     "iopub.status.idle": "2023-01-10T16:01:44.304181Z",
     "shell.execute_reply": "2023-01-10T16:01:44.303897Z",
     "shell.execute_reply.started": "2023-01-10T16:01:44.300784Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDADE_MATERNA\n",
      "1\n",
      "PESO_INICIAL\n",
      "2\n",
      "IMC\n",
      "3\n",
      "NUMERO_CONSULTAS_PRE_NATAL\n",
      "4\n",
      "IDADE_GESTACIONAL_ADMISSAO\n",
      "5\n",
      "SEMANAS_GESTACAO_PARTO\n",
      "6\n",
      "PESO_ADMISSAO_INTERNAMENTO\n",
      "7\n",
      "GS\n",
      "8\n",
      "BISHOP_DILATACAO\n",
      "9\n",
      "CIGARROS\n",
      "10\n",
      "CESARIANAS_ANTERIOR\n",
      "11\n",
      "A_PARA\n",
      "12\n",
      "EUTOCITO_ANTERIOR\n",
      "13\n",
      "APRESENTACAO_NO_PARTO\n",
      "14\n",
      "VIGIADA\n",
      "15\n",
      "APRESENTACAO_ADMISSAO\n",
      "16\n",
      "BISHOP_SCORE\n",
      "17\n",
      "TIPO_GRAVIDEZ\n",
      "18\n",
      "VIGIADA_PARICULAR\n",
      "19\n",
      "DIABETES_GESTACIONAL\n",
      "20\n",
      "TRAB_PARTO_NO_PARTO\n",
      "21\n",
      "BISHOP_DESCIDA\n",
      "22\n",
      "BISHOP_CONSISTENCIA\n",
      "23\n",
      "BACIA\n",
      "24\n",
      "VIGIADA_NESTE_HOSPITAL\n",
      "25\n",
      "RPM\n",
      "26\n",
      "FORCEPS_ANTERIOR\n",
      "27\n",
      "TIPO_PARTO\n",
      "28\n",
      "TRAB_PARTO_ENTRADA_INDUZIDO\n",
      "29\n",
      "BISHOP_EXTINCAO\n",
      "30\n",
      "TRAB_PARTO_ENTRADA_ESPONTANEO\n",
      "31\n",
      "VENTOSAS_ANTERIOR\n",
      "32\n",
      "BISHOP_POSICAO\n",
      "33\n",
      "A_GESTA\n",
      "34\n",
      "VIGIADA_CENTRO_SAUDE\n",
      "35\n",
      "GRUPO_ROBSON\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for k in silo_imputed[0].columns:\n",
    "    print(k)\n",
    "    print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f83631d2-0706-4861-9317-360496b2fdb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T16:04:50.324385Z",
     "iopub.status.busy": "2023-01-10T16:04:50.323836Z",
     "iopub.status.idle": "2023-01-10T16:04:50.333532Z",
     "shell.execute_reply": "2023-01-10T16:04:50.332797Z",
     "shell.execute_reply.started": "2023-01-10T16:04:50.324325Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"col_types.json\", \"r\") as infile:\n",
    "    col_types = json.load(infile)\n",
    "int_cols=col_types[\"int\"]\n",
    "cat_cols=col_types[\"cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ffa4879-84c3-4ead-b974-7c6cc45c60d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T15:59:00.293082Z",
     "iopub.status.busy": "2023-01-10T15:59:00.292667Z",
     "iopub.status.idle": "2023-01-10T15:59:00.304674Z",
     "shell.execute_reply": "2023-01-10T15:59:00.303522Z",
     "shell.execute_reply.started": "2023-01-10T15:59:00.293057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cat_cols = [\"GS\",\n",
    "                   \"A_PARA\",\n",
    "                   \"A_GESTA\",\n",
    "                   \"TIPO_GRAVIDEZ\",\n",
    "                   \"VIGIADA\",\n",
    "                   \"VIGIADA_CENTRO_SAUDE\",\n",
    "                   \"VIGIADA_NESTE_HOSPITAL\",\n",
    "                   \"APRESENTACAO_ADMISSAO\",\n",
    "                   \"TRAB_PARTO_ENTRADA_ESPONTANEO\",\n",
    "                   \"TIPO_PARTO\",\n",
    "                   \"APRESENTACAO_NO_PARTO\",\n",
    "                   \"TRAB_PARTO_NO_PARTO\",\n",
    "                   \"GRUPO_ROBSON\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28360d73-c7dd-4a71-9d26-6645946596e9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c645fa55-c288-4c87-a72e-c51a91e77e1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T15:23:07.616101Z",
     "iopub.status.busy": "2023-01-10T15:23:07.615673Z",
     "iopub.status.idle": "2023-01-10T15:23:07.623506Z",
     "shell.execute_reply": "2023-01-10T15:23:07.622304Z",
     "shell.execute_reply.started": "2023-01-10T15:23:07.616072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_classes(dfs, target):\n",
    "    final_list = []\n",
    "    for df in dfs:\n",
    "        for e in df[target].unique():\n",
    "            final_list.append(e) if e not in final_list else final_list\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ac44c0-d75b-4ebb-a98c-cfbe4ddd5c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T15:23:07.839383Z",
     "iopub.status.busy": "2023-01-10T15:23:07.838988Z",
     "iopub.status.idle": "2023-01-10T15:23:07.873815Z",
     "shell.execute_reply": "2023-01-10T15:23:07.873546Z",
     "shell.execute_reply.started": "2023-01-10T15:23:07.839347Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_dict = {}\n",
    "for col in cat_cols:\n",
    "    classes_dict[col] = get_all_classes(silo_imputed, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c4c410f-8acd-4cb2-8cff-1bd1729e2b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T15:23:08.153556Z",
     "iopub.status.busy": "2023-01-10T15:23:08.152902Z",
     "iopub.status.idle": "2023-01-10T15:23:08.162945Z",
     "shell.execute_reply": "2023-01-10T15:23:08.162068Z",
     "shell.execute_reply.started": "2023-01-10T15:23:08.153504Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_global_model_init(g_model, X_train, y_train, model_type):\n",
    "    # threshold = get_best_threshold(g_model[\"myvoting\"], X_train, y_train)\n",
    "    #  g_model[\"myvoting\"].set_threshold(threshold[0])\n",
    "    g_model[\"ensemble\"].fit(X_train, y_train)  #only one to use // so we can use it. Does not change the models\n",
    "    #   g_model[\"stacking\"].fit(X_train, y_train)\n",
    "    return g_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d535093-03b1-47e4-bd09-090a40df9362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T15:23:08.461299Z",
     "iopub.status.busy": "2023-01-10T15:23:08.460635Z",
     "iopub.status.idle": "2023-01-10T15:23:08.475839Z",
     "shell.execute_reply": "2023-01-10T15:23:08.475186Z",
     "shell.execute_reply.started": "2023-01-10T15:23:08.461245Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_variables_and_transform_variables(df, target, cat_cols, int_cols, class_list=None, threshold=12,\n",
    "                                               nr_rows=25):\n",
    "    if class_list:\n",
    "        missing_class = list(set(class_list) - set(df[str(target)].unique()))\n",
    "        if len(missing_class) > 0:\n",
    "            # print(\"missing class:\",missing_class)\n",
    "            #  print(\"existing class:\",df[str(target)].unique())\n",
    "            for c in missing_class:\n",
    "                df = dummy_row_creation(df, target, c, int_cols, cat_cols, nr_rows)\n",
    "    s = df[target].value_counts().le(threshold)\n",
    "    to_smote = list(s[s].index.values)\n",
    "    #print(\"vars to be enhanced\",to_smote) \n",
    "    # transform the dataset\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "    if len(to_smote) > 0:\n",
    "        smote_params = {}\n",
    "        for e in to_smote:\n",
    "            smote_params[e] = nr_rows\n",
    "        ros = RandomOverSampler(random_state=0, sampling_strategy=smote_params)\n",
    "\n",
    "        X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "        #if not present\n",
    "        return X_resampled, y_resampled\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08f28863-a81f-4e85-92f0-9db0fab7a713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T15:23:09.901090Z",
     "iopub.status.busy": "2023-01-10T15:23:09.900533Z",
     "iopub.status.idle": "2023-01-10T15:23:09.914346Z",
     "shell.execute_reply": "2023-01-10T15:23:09.913427Z",
     "shell.execute_reply.started": "2023-01-10T15:23:09.900992Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def auprc_multiclass(y_test, y_score, full_classes):\n",
    "    #print(y_score)\n",
    "    #print(full_classes)\n",
    "    #print(y_test)\n",
    "    #print(y_test.shape)\n",
    "    y_test_multilabel = label_binarize(y_test, classes=full_classes)\n",
    "    #y_test_multilabel=label_binarize(y_test, classes=full_classes)\n",
    "    try:\n",
    "        auprc = average_precision_score(\n",
    "            y_test_multilabel, y_score, average=\"weighted\"\n",
    "        )\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error on\", \"auprc score calculate\", e, \"y_score --->\", y_score)\n",
    "        print(\"Error on\", \"auprc score calculate\", e, \" y_test--->\", y_test_multilabel)\n",
    "\n",
    "        #result[\"silo\" + str(idx + 1) + \"_roc_auc_score_global\"] = np.nan\n",
    "        return np.nan\n",
    "    #print(auprc)\n",
    "    return auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a37763c3-40c6-4835-992a-691e7de41dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T15:23:13.708569Z",
     "iopub.status.busy": "2023-01-10T15:23:13.708147Z",
     "iopub.status.idle": "2023-01-10T15:23:13.735778Z",
     "shell.execute_reply": "2023-01-10T15:23:13.735398Z",
     "shell.execute_reply.started": "2023-01-10T15:23:13.708537Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_federated_model(\n",
    "        silos, target, metrics, cv, int_cols, cat_cols, tuned_parameters, model, full_classes, model_type=\"myvoting\",\n",
    "        debug_mode=False\n",
    "):\n",
    "    \"\"\"\n",
    "    for every silo, trains and local model with hyperparameter tuning (CV)\n",
    "    After that, creates a global_model and with all locals and global evaluates on the test set several metrics\n",
    "    remove low frequency target (below 4) in order to get proper metric values (weighted f1 and auc)\n",
    "    \"\"\"\n",
    "    grid_list = []\n",
    "    result = {}\n",
    "    models = []\n",
    "    test_sets = []\n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    f = open(\"logs/log_\" + str(type(model).__name__) + \".txt\", \"a\")\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d - %H:%M\")\n",
    "    f.write(date_time + \"\\n\")\n",
    "    for idx, silo in enumerate(silos):\n",
    "        if debug_mode:\n",
    "            print(\"silo\", str(idx))\n",
    "            print(np.random.randint(1, 20))\n",
    "        if \"random_state\" in model.get_params().keys():\n",
    "            model.set_params(random_state=np.random.randint(1, 20))\n",
    "        #   print(model.get_params())\n",
    "        #     s_model = OneVsRestClassifier(model)\n",
    "        clf = GridSearchCV(\n",
    "            model, tuned_parameters, cv=RepeatedStratifiedKFold(n_splits=cv, n_repeats=2), n_jobs=-2, scoring='f1_micro'\n",
    "        )\n",
    "        nr_classes = silo[target].unique()\n",
    "        X, y = evaluate_variables_and_transform_variables(silo, target, int_cols, cat_cols, full_classes[target])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y\n",
    "        )\n",
    "\n",
    "        test_sets.append((y_test, X_test))\n",
    "        X_train_list.append(X_train)\n",
    "        y_train_list.append(y_train)\n",
    "        models.append(clf.fit(X_train, y_train).best_estimator_)\n",
    "        grid_list.append(clf)\n",
    "        print(clf.best_params_)\n",
    "    w = define_weights(grid_list)  #explain paper -> define weights based on scores / sum of all scores\n",
    "    f.write(\"w,\" + \" \" + str(w) + \"\\n\")\n",
    "    global_model = create_global_model(models, \"voting\",\n",
    "                                       w)  #explain paper intialize class of EnsembleVoteClassifier from mlxtend with weigths\n",
    "    global_model = prepare_global_model_init(  #explain paper does fit with a random train set to use it further\n",
    "        global_model, X_train_list[0], y_train_list[0], model_type\n",
    "    )\n",
    "\n",
    "    for idx, tests in enumerate(test_sets):\n",
    "        y_pred_l_auc = models[idx].predict_proba(tests[1])\n",
    "        y_pred_g_auc = global_model[model_type].predict_proba(tests[1])\n",
    "\n",
    "        y_pred_l = models[idx].predict(tests[1])\n",
    "        y_pred_g = global_model[model_type].predict(tests[1])\n",
    "        classes_score = global_model[model_type].classes_\n",
    "        #  print(\"classses model\",str(classes_score))\n",
    "        if len(nr_classes) < 3:\n",
    "            y_pred_l_auc = y_pred_l\n",
    "            y_pred_g_auc = y_pred_g\n",
    "        for metric in metrics:\n",
    "            if metric == \"auprc\":\n",
    "                result[\"silo\" + str(idx + 1) + \"_auprc_local\"] = auprc_multiclass(tests[0], y_pred_l_auc, classes_score)\n",
    "                #average_precision_score(\n",
    "                #   y_pred_l, tests[0],average=\"weighted\"\n",
    "                #)\n",
    "                result[\"silo\" + str(idx + 1) + \"_auprc_global\"] = auprc_multiclass(tests[0], y_pred_g_auc,\n",
    "                                                                                   classes_score)\n",
    "            #  average_precision_score(\n",
    "            #      y_pred_g, tests[0],average=\"weighted\"\n",
    "            #  )\n",
    "            if metric == \"roc_auc_score\":\n",
    "                try:\n",
    "                    result[\n",
    "                        \"silo\" + str(idx + 1) + \"_roc_auc_score_local\"\n",
    "                        ] = roc_auc_score(y_true=tests[0], y_score=y_pred_l_auc, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    f.write(\"Error on local-silo\" + \" \" + str(idx + 1) + \"\\n\")\n",
    "                    f.write(\"roc score calculate\" + \" \" + str(e) + \" --->\" + str(y_pred_l_auc) + \"\\n\")\n",
    "                    result[\"silo\" + str(idx + 1) + \"_roc_auc_score_local\"] = np.nan\n",
    "                try:\n",
    "                    result[\n",
    "                        \"silo\" + str(idx + 1) + \"_roc_auc_score_global\"\n",
    "                        ] = roc_auc_score(y_true=tests[0], y_score=y_pred_g_auc, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    f.write(\"Error on global-silo \" + str(idx + 1) + \"\\n\")\n",
    "                    f.write(\"roc score calculate \" + str(e) + \" ---> \" + str(y_pred_g_auc) + \"\\n\")\n",
    "                    result[\"silo\" + str(idx + 1) + \"_roc_auc_score_global\"] = np.nan\n",
    "            if metric == \"f1\":\n",
    "                result[\"silo\" + str(idx + 1) + \"_f1_local\"] = f1_score(\n",
    "                    y_pred=y_pred_l, y_true=tests[0], average=\"weighted\"\n",
    "                )\n",
    "                result[\"silo\" + str(idx + 1) + \"_f1_global\"] = f1_score(\n",
    "                    y_pred=y_pred_g, y_true=tests[0], average=\"weighted\"\n",
    "                )\n",
    "\n",
    "    f.close()\n",
    "    return result, global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e0a8e52-beef-4b80-bc99-175739bc969b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T15:23:14.212465Z",
     "iopub.status.busy": "2023-01-10T15:23:14.211715Z",
     "iopub.status.idle": "2023-01-10T15:23:14.230293Z",
     "shell.execute_reply": "2023-01-10T15:23:14.229728Z",
     "shell.execute_reply.started": "2023-01-10T15:23:14.212411Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evalute_full_method(\n",
    "        targets,\n",
    "        silos,\n",
    "        metrics,\n",
    "        tuned_parameters,\n",
    "        cv, int_cols, cat_cols, full_classes,\n",
    "        model=SGDClassifier(),\n",
    "        repeats=2,\n",
    "        model_type=\"myvoting\", debug_mode=False\n",
    "):\n",
    "    total = {k: [] for k in targets}\n",
    "    np.random.seed(42)\n",
    "    score_to_save = 0\n",
    "    mode_to_save = None\n",
    "    for target in targets:\n",
    "        print(\"evaluating \" + target + \"... \")\n",
    "        total[target] = {}\n",
    "        total[target][\"models\"] = []\n",
    "        total[target][\"g_model\"] = []\n",
    "        for metric in metrics:\n",
    "            for silonr, silo in enumerate(silos):\n",
    "                total[target][\"silo\" + str(silonr + 1) + \"_\" + metric + \"_local\"] = []\n",
    "                total[target][\"silo\" + str(silonr + 1) + \"_\" + metric + \"_global\"] = []\n",
    "        for i in range(repeats):\n",
    "            t = evaluate_federated_model(\n",
    "                silos=silos,\n",
    "                target=target,\n",
    "                metrics=metrics,\n",
    "                tuned_parameters=tuned_parameters,\n",
    "                cv=cv, int_cols=int_cols, cat_cols=cat_cols,\n",
    "                model=model, full_classes=full_classes,\n",
    "                model_type=model_type, debug_mode=debug_mode\n",
    "            )\n",
    "            for metric in metrics:\n",
    "                for silonr, silo in enumerate(silos):\n",
    "                    total[target][\n",
    "                        \"silo\" + str(silonr + 1) + \"_\" + metric + \"_local\"\n",
    "                        ].append(t[0][\"silo\" + str(silonr + 1) + \"_\" + metric + \"_local\"])\n",
    "\n",
    "                    total[target][\n",
    "                        \"silo\" + str(silonr + 1) + \"_\" + metric + \"_global\"\n",
    "                        ].append(t[0][\"silo\" + str(silonr + 1) + \"_\" + metric + \"_global\"])\n",
    "        save_zipped_model(target, model, model_type, t[1])\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbf911-37d1-4009-978c-e3f0d3ddb302",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b30f1ae-96ac-43d8-b6fe-71198647cbaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating GS... \n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating A_PARA... \n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating A_GESTA... \n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating TIPO_GRAVIDEZ... \n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating VIGIADA... \n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating VIGIADA_CENTRO_SAUDE... \n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating VIGIADA_NESTE_HOSPITAL... \n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating APRESENTACAO_ADMISSAO... \n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating TRAB_PARTO_ENTRADA_ESPONTANEO... \n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating TIPO_PARTO... \n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating APRESENTACAO_NO_PARTO... \n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating TRAB_PARTO_NO_PARTO... \n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "evaluating GRUPO_ROBSON... \n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.0001, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "{'alpha': 0.01, 'l1_ratio': 0.05, 'loss': 'modified_huber'}\n",
      "CPU times: user 15min 18s, sys: 2min 34s, total: 17min 53s\n",
      "Wall time: 52min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 1h1m\n",
    "# stochastic gradient\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "total = evalute_full_method(\n",
    "    repeats=REPS,\n",
    "    targets=target_cat_cols,\n",
    "    metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "    silos=silo_imputed,\n",
    "    cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "    tuned_parameters=[{\"alpha\": [0.0001, 0.01,0.001], \"l1_ratio\": [0.05],\"loss\":[\"log_loss\",\"modified_huber\"]}],\n",
    "    model_type=\"ensemble\", debug_mode=False\n",
    ")\n",
    "alarm\n",
    "with open(\"raw_classif_sgd.json\", \"w\") as f:\n",
    "    json.dump(total, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa47380-097f-4f9a-9327-2cc4ddd8d797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final = get_stats(total)\n",
    "#plot_paper_grade_error(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed00343-62e0-4a7b-a7ab-658580198cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ttest_data = get_ttest(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6260979-7e46-43d4-a42d-f974cc06cccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sgd = create_mega_table(total, \"SGD\")\n",
    "df_sgd.head()\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_sgd.to_csv(\"results/classif_sgd\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e0efa7",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7740fb-e302-4cf6-9f54-eaf108361d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# decision tree\n",
    "#Wall time: 21min\n",
    "\n",
    "# voting  o unico justo. stacking com o learn com um X train fica mt bom nesse e mau nos outros\n",
    "# ensemble ainda n sei bem\n",
    "total_dt = evalute_full_method(\n",
    "    targets=target_cat_cols,\n",
    "    metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "    silos=silo_imputed,\n",
    "    cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "    tuned_parameters=[\n",
    "        {\"criterion\": [\"gini\", \"entropy\"], \"max_features\": [\"log2\", \"auto\"]}\n",
    "    ],\n",
    "    model=DecisionTreeClassifier(),\n",
    "    repeats=REPS,\n",
    "    model_type=\"ensemble\",\n",
    ")\n",
    "alarm\n",
    "with open(\"raw_classif_dt.json\", \"w\") as f:\n",
    "    json.dump(total_dt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a49ae-c660-48ff-9fd2-d9b39767b490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_dt = get_stats(total_dt)\n",
    "#plot_paper_grade_error(final_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8952a9-b703-4406-a1de-57770ade4ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tt = get_ttest(total_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3cd950-d8e7-4d58-b630-1ec50b126f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dt = create_mega_table(total_dt, \"decisionTree\")\n",
    "df_dt.head()\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_dt.to_csv(\"results/classif_dt\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a3e56-7e9a-4f83-a038-288c77c615a1",
   "metadata": {},
   "source": [
    "## Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ffecf-7ffa-4afe-a071-ef151e020144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Wall time: 20min\n",
    "\n",
    "total_nb = evalute_full_method(\n",
    "    targets=target_cat_cols,\n",
    "    metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "    silos=silo_imputed,\n",
    "    cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "    tuned_parameters=[{\"var_smoothing\": [1e-9, 1e-8, 1e-7]}],\n",
    "    model=GaussianNB(),\n",
    "    repeats=REPS,\n",
    "    model_type=\"ensemble\",\n",
    ")\n",
    "alarm\n",
    "with open(\"raw_classif_nb.json\", \"w\") as f:\n",
    "    json.dump(total_nb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40316af-7ee0-4c60-89fd-3249a76b17f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_nb = get_stats(total_nb)\n",
    "#plot_paper_grade_error(final_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3193328f-5e16-49d7-b516-102908d16bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_nb = create_mega_table(total_nb, \"NaiveBayes\")\n",
    "df_nb.head()\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_nb.to_csv(\"results/classif_nb\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce2d51-35fe-440a-a554-818100c1c843",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874599d3-4d2d-43c5-86f6-45ec7421c2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#3h 40min\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "total_knn = evalute_full_method(\n",
    "    targets=target_cat_cols,\n",
    "    metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "    silos=silo_imputed,\n",
    "    cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "    tuned_parameters={\n",
    "        \"n_neighbors\": [5, 7, 10],\n",
    "        \"p\": [1, 2]\n",
    "    },\n",
    "    model=KNeighborsClassifier(),\n",
    "    repeats=REPS,\n",
    "    model_type=\"ensemble\",\n",
    ")\n",
    "alarm\n",
    "with open(\"raw_classif_knn.json\", \"w\") as f:\n",
    "    json.dump(total_knn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a63587-e1f2-41a7-9895-f7a623cb5fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_knn = create_mega_table(total_knn, \"KNN\")\n",
    "df_knn.head()\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_knn.to_csv(\"results/classif_knn\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad85b92-456b-44cc-9838-bf666cbea720",
   "metadata": {},
   "source": [
    "## ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76c569-bcf3-4a79-93e1-ca8a7e4fb300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Wall time: 1h 20m\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "total_adaboost = evalute_full_method(\n",
    "    targets=target_cat_cols,\n",
    "    metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "    silos=silo_imputed,\n",
    "    cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "    tuned_parameters={\n",
    "        \"learning_rate\": [1, 2, 0.5],\n",
    "        \"n_estimators\": [25, 50]\n",
    "    },\n",
    "    model=AdaBoostClassifier(),\n",
    "    repeats=REPS,\n",
    "    model_type=\"ensemble\",\n",
    ")\n",
    "alarm\n",
    "with open(\"raw_classif_ada.json\", \"w\") as f:\n",
    "    json.dump(total_adaboost, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96085ee0-3383-4950-b5f7-e2b340de9bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_adaboost = get_stats(total_adaboost)\n",
    "#plot_paper_grade_error(final_adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f0b2e-6c48-4f58-8743-aba8cb196e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_adaboost = create_mega_table(total_adaboost, \"ADABOOST\")\n",
    "df_adaboost.head()\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_adaboost.to_csv(\"results/classif_adaboost\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7911d-d090-4c88-9989-d58b8a49f713",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756478fb-3f88-4a16-9787-edc54e71fdc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Wall time: 1h13m\n",
    "\n",
    "total_nn = evalute_full_method(\n",
    "    targets=target_cat_cols,\n",
    "    metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "    silos=silo_imputed,\n",
    "    cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "    tuned_parameters={\n",
    "        \"solver\": [\"lbfgs\"], \"learning_rate_init\": [0.001, 1e-4], \"max_iter\": [10000, 500],\n",
    "        \"hidden_layer_sizes\": [(100,)],\n",
    "        \"alpha\": [1e-5, 1e-4], \"learning_rate\": [\"adaptive\"], \"tol\": [10, 20]\n",
    "    },\n",
    "    model=MLPClassifier(),\n",
    "    repeats=REPS,\n",
    "    model_type=\"ensemble\",\n",
    ")\n",
    "alarm\n",
    "with open(\"raw_classif_nn.json\", \"w\") as f:\n",
    "    json.dump(total_nb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b742d-321c-44cb-8540-f40ff1b44c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_nn = get_stats(total_nn)\n",
    "#plot_paper_grade_error(final_adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ff888-fb23-4904-aa43-7008a68ff41a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_nn = create_mega_table(total_nn, \"NN\")\n",
    "df_nn.head()\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_nn.to_csv(\"results/classif_nn\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5ab1b-3ec3-49a5-a240-76b92ecd68ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## compile all DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08012e8-0d51-4fe7-9fee-6305efb318b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "result = pd.concat([df_sgd, df_dt, df_nb, df_knn, df_adaboost, df_nn], axis=0)\n",
    "result.to_csv(\"results/classif_result_df\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5c792-148b-4eb8-82f5-b946837d5fc4",
   "metadata": {},
   "source": [
    "# Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a448a41-b7fb-4235-a1cd-d130f25342f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_total_model_and_evaluate(\n",
    "        silos,\n",
    "        targets,\n",
    "        parameters,\n",
    "        global_model_name, cat_cols, int_cols,\n",
    "        full_classes,\n",
    "        model,\n",
    "        cv=10,\n",
    "        nr_repeats=10, samplingsilo=False\n",
    "):\n",
    "    np.random.seed(42)\n",
    "    if samplingsilo:\n",
    "        minisilos = [silo.sample(1000) if len(silo) > 1000 else silo for silo in silos]  # keep same nr rows\n",
    "    minisilos = [silo for silo in silos]  #knn takes way too long\n",
    "    full_data = pd.concat(minisilos).reset_index(drop=True)\n",
    "    full_metric = defaultdict(dict)\n",
    "    f = open(\"logs/centralised_\" + str(type(global_model_name).__name__) + \".txt\", \"w\")\n",
    "    for target in targets:\n",
    "\n",
    "        print(\"testing....\", target, \"..................\" * 3)\n",
    "        full_metric[target] = {\n",
    "            \"total\": {\"auc\": [], \"f1\": [], \"auprc\": []},\n",
    "            \"global\": {\"auc\": [], \"f1\": [], \"auprc\": []},\n",
    "        }\n",
    "        global_model = load_model_from_zip(target + \"_\" + str(type(global_model_name).__name__) + \"_ensemble\")\n",
    "        # print(global_model)\n",
    "\n",
    "        for i in range(nr_repeats):\n",
    "            adpat_value = False\n",
    "            r_s = np.random.randint(1, nr_repeats)\n",
    "            argspec = model.get_params()\n",
    "            if \"random_state\" in argspec.keys():\n",
    "\n",
    "                total_clf = GridSearchCV(\n",
    "                    model.set_params(random_state=r_s),\n",
    "                    param_grid=parameters,\n",
    "                    cv=RepeatedStratifiedKFold(n_splits=cv, n_repeats=2),\n",
    "                    n_jobs=-2,\n",
    "                )\n",
    "            else:\n",
    "                total_clf = GridSearchCV(\n",
    "                    model.set_params(),\n",
    "                    param_grid=parameters,\n",
    "                    cv=RepeatedStratifiedKFold(n_splits=cv, n_repeats=2),\n",
    "                    n_jobs=-2,\n",
    "                )\n",
    "            # print(i,target)\n",
    "            X, y = evaluate_variables_and_transform_variables(full_data, target, cat_cols=cat_cols, int_cols=int_cols,\n",
    "                                                              class_list=full_classes[target])\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, stratify=y\n",
    "            )\n",
    "\n",
    "            total_clf.fit(X_train, y_train)\n",
    "            g_model = prepare_global_model(\n",
    "                global_model[\"ensemble\"], X_train, y_train\n",
    "            )\n",
    "            #pred centralised on total\n",
    "            y_pred_t_auc = y_pred_t = total_clf.best_estimator_.predict(X_test)\n",
    "            #pred distributed on total\n",
    "            y_pred_g_auc = y_pred_g = g_model.predict(X_test)\n",
    "            classes_score = g_model.classes_\n",
    "            #  print(\"classses model\",str(classes_score))\n",
    "            if len(full_classes[target]) > 3:\n",
    "                y_pred_t_auc = total_clf.best_estimator_.predict_proba(X_test)\n",
    "                y_pred_g_auc = g_model.predict_proba(X_test)\n",
    "\n",
    "            full_metric[target][\"total\"][\"auc\"].append(\n",
    "                roc_auc_score(y_score=y_pred_t_auc, y_true=y_test, multi_class=\"ovr\")\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                full_metric[target][\"global\"][\"auc\"].append(\n",
    "                    roc_auc_score(y_score=y_pred_g_auc, y_true=y_test, multi_class=\"ovr\")\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                f.write(\"ERROR: Y_PRED_G_AUC\\n\")\n",
    "                #np.savetxt(f,y_pred_g_auc)\n",
    "                any_nan = np.any(np.isnan(y_pred_g_auc))\n",
    "                local_nan = np.argwhere(np.isnan(y_pred_g_auc))\n",
    "                f.write(str(local_nan))\n",
    "                # f.write(str(y_pred_g_auc[np.argwhere(np.isnan(y_pred_g_auc))]))\n",
    "                #f.write(str(X_test[np.argwhere(np.isnan(y_pred_g_auc))]))\n",
    "                #f.write(str(X_test[2429,:]))\n",
    "                f.write(str(any_nan))\n",
    "                f.write(str(np.sum(any_nan)))\n",
    "\n",
    "                #                print(\"ERROR: on AUC\",e)\n",
    "                f.write(\"ERROR: the sum of nan in y_pred_g_auc is:\" + str(np.sum(np.isnan(y_pred_g_auc))) + \"\\n\")\n",
    "\n",
    "                #print(y_pred_g_auc.shape)\n",
    "                non_nan_pred = y_pred_g_auc[~np.isnan(y_pred_g_auc)]\n",
    "                non_nan_pred_2 = y_pred_g_auc[~np.isnan(y_pred_g_auc).any(axis=1), :]\n",
    "                # x[ ~np.isnan(x).any(axis=1),:]\n",
    "                adpat_value = True\n",
    "                #print(local_nan[0])\n",
    "                #print(local_nan[0][0])\n",
    "                #print(local_nan[0][1])\n",
    "                #print(local_nan[:,0])\n",
    "                nan_indexes = np.unique(local_nan[:, 0]).tolist()\n",
    "                # print(str(y_test.reset_index()))\n",
    "                non_nan_test = y_test.reset_index().drop(index=nan_indexes)\n",
    "                non_nan_test = non_nan_test.drop(columns=[\"index\"])\n",
    "                f.write(str(non_nan_test) + \"\\n\")\n",
    "                f.write(str(non_nan_pred.shape) + \"\\n\")\n",
    "                f.write(str(non_nan_pred_2.shape) + \"\\n\")\n",
    "\n",
    "                non_nan_result = roc_auc_score(y_score=non_nan_pred_2, y_true=non_nan_test, multi_class=\"ovr\")\n",
    "                full_metric[target][\"global\"][\"auc\"].append(non_nan_result)\n",
    "\n",
    "            full_metric[target][\"total\"][\"f1\"].append(\n",
    "                f1_score(y_pred_t, y_test, average=\"weighted\")\n",
    "            )\n",
    "\n",
    "            full_metric[target][\"global\"][\"f1\"].append(\n",
    "                f1_score(y_pred_g, y_test, average=\"weighted\")\n",
    "            )\n",
    "\n",
    "            full_metric[target][\"total\"][\"auprc\"].append(\n",
    "                auprc_multiclass(y_test, y_pred_t_auc, classes_score)\n",
    "            )\n",
    "            if adpat_value:\n",
    "                full_metric[target][\"global\"][\"auprc\"].append(\n",
    "                    auprc_multiclass(non_nan_test, non_nan_pred_2, classes_score))\n",
    "            else:\n",
    "                full_metric[target][\"global\"][\"auprc\"].append(auprc_multiclass(y_test, y_pred_g_auc, classes_score))\n",
    "            adpat_value = False\n",
    "        save_zipped_model(target, model, \"centralised\", total_clf)\n",
    "\n",
    "    f.close()\n",
    "    return full_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4ed3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_total_model(\n",
    "        silos,\n",
    "        targets,\n",
    "        parameters,\n",
    "        global_model_name, cat_cols, int_cols,\n",
    "        full_classes,\n",
    "        model,\n",
    "        cv=10,\n",
    "        nr_repeats=10, samplingsilo=False\n",
    "):\n",
    "    np.random.seed(42)\n",
    "    if samplingsilo:\n",
    "        minisilos = [silo.sample(1000) if len(silo) > 1000 else silo for silo in silos]  # keep same nr rows\n",
    "    minisilos = [silo for silo in silos]  #knn takes way too long\n",
    "    full_data = pd.concat(minisilos).reset_index(drop=True)\n",
    "    full_metric = defaultdict(dict)\n",
    "    f = open(\"logs/centralised_\" + str(type(global_model_name).__name__) + \".txt\", \"w\")\n",
    "    for target in targets:\n",
    "\n",
    "        print(\"testing....\", target, \"..................\" * 3)\n",
    "        full_metric[target] = {\n",
    "            \"total\": {\"auc\": [], \"f1\": [], \"auprc\": []}        }\n",
    "\n",
    "        r_s = np.random.randint(1, nr_repeats)\n",
    "        argspec = model.get_params()\n",
    "        if \"random_state\" in argspec.keys():\n",
    "\n",
    "            total_clf = GridSearchCV(\n",
    "                model.set_params(random_state=r_s),\n",
    "                param_grid=parameters,\n",
    "                cv=RepeatedStratifiedKFold(n_splits=cv, n_repeats=2),\n",
    "                n_jobs=-2,\n",
    "            )\n",
    "        else:\n",
    "            total_clf = GridSearchCV(\n",
    "                model.set_params(),\n",
    "                param_grid=parameters,\n",
    "                cv=RepeatedStratifiedKFold(n_splits=cv, n_repeats=2),\n",
    "                n_jobs=-2,\n",
    "            )\n",
    "        # print(i,target)\n",
    "        X, y = evaluate_variables_and_transform_variables(full_data, target, cat_cols=cat_cols, int_cols=int_cols,\n",
    "                                                            class_list=full_classes[target])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y\n",
    "        )\n",
    "\n",
    "        total_clf.fit(X_train, y_train)\n",
    "        y_pred_t_auc = y_pred_t = total_clf.best_estimator_.predict(X_test)\n",
    "        classes_score = total_clf.best_estimator_.classes_\n",
    "        if len(full_classes[target]) > 3:\n",
    "            y_pred_t_auc = total_clf.best_estimator_.predict_proba(X_test)\n",
    "\n",
    "        full_metric[target][\"total\"][\"auc\"].append(\n",
    "            roc_auc_score(y_score=y_pred_t_auc, y_true=y_test, multi_class=\"ovr\")\n",
    "        )\n",
    "\n",
    "        full_metric[target][\"total\"][\"auprc\"].append(\n",
    "            auprc_multiclass(y_test, y_pred_t_auc, classes_score)\n",
    "        )\n",
    "    save_zipped_model(target, model, \"centralised\", total_clf)\n",
    "\n",
    "    f.close()\n",
    "    return full_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4332d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeada51-2fe1-4689-957d-efac808e7b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2h 55min without SGD and KNN\n",
    "data_dict = {\n",
    "    \"decisionTree\": [DecisionTreeClassifier(), [{\"criterion\": [\"gini\", \"entropy\"], \"max_features\": [\"log2\", \"auto\"]}]],\n",
    "    \"NaiveBayes\": [GaussianNB(), [{\"var_smoothing\": [1e-9, 1e-8, 1e-7]}]],\n",
    "    \"ADABOOST\": [AdaBoostClassifier(), {\"learning_rate\": [1, 2, 0.5], \"n_estimators\": [25, 50]}],\n",
    "    \"NN\": [MLPClassifier(), {\"solver\": [\"lbfgs\"], \"learning_rate_init\": [0.001, 1e-4], \"max_iter\": [10000, 500],\n",
    "                             \"hidden_layer_sizes\": [(100,)],\n",
    "                             \"alpha\": [1e-5, 1e-4], \"learning_rate\": [\"adaptive\"], \"tol\": [10, 20]}]\n",
    "}\n",
    "for k, v in data_dict.items():\n",
    "    print(k)\n",
    "    result_dict[k] = create_total_model_and_evaluate(\n",
    "        silos=silo_imputed,\n",
    "        targets=target_cat_cols,\n",
    "        parameters=v[1], cat_cols=cat_cols, int_cols=int_cols,\n",
    "        global_model_name=v[0], full_classes=classes_dict,\n",
    "        model=v[0], samplingsilo=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65bf0475-2396-4109-9fe2-0ba033e0a8bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD\n",
      "testing.... GS ......................................................\n",
      "testing.... A_PARA ......................................................\n",
      "testing.... A_GESTA ......................................................\n",
      "testing.... TIPO_GRAVIDEZ ......................................................\n",
      "testing.... VIGIADA ......................................................\n",
      "testing.... VIGIADA_CENTRO_SAUDE ......................................................\n",
      "testing.... VIGIADA_NESTE_HOSPITAL ......................................................\n",
      "testing.... APRESENTACAO_ADMISSAO ......................................................\n",
      "testing.... TRAB_PARTO_ENTRADA_ESPONTANEO ......................................................\n",
      "testing.... TIPO_PARTO ......................................................\n",
      "testing.... APRESENTACAO_NO_PARTO ......................................................\n",
      "testing.... TRAB_PARTO_NO_PARTO ......................................................\n",
      "testing.... GRUPO_ROBSON ......................................................\n"
     ]
    }
   ],
   "source": [
    "#2h 46min\n",
    "data_dict = {\"SGD\": [SGDClassifier(),[{\"alpha\": [0.0001, 0.01,0.001], \"l1_ratio\": [0.05],\"loss\":[\"log_loss\",\"modified_huber\"]}]]}\n",
    "\n",
    "for k, v in data_dict.items():\n",
    "    print(k)\n",
    "    result_dict[k] = create_total_model_and_evaluate(\n",
    "        silos=silo_imputed,\n",
    "        targets=target_cat_cols,\n",
    "        parameters=v[1], cat_cols=cat_cols, int_cols=int_cols,\n",
    "        global_model_name=v[0], full_classes=classes_dict,\n",
    "        model=v[0], samplingsilo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1a448-1c92-4097-b59c-1961e2a5955d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dict = {\"KNN\": [KNeighborsClassifier(), {\"n_neighbors\": [5, 7, 10], \"p\": [1, 2]}]}\n",
    "\n",
    "for k, v in data_dict.items():\n",
    "    for t in target_cat_cols:\n",
    "        print(t)\n",
    "        print(k)\n",
    "        result_dict[k] = create_total_model(\n",
    "            silos=silo_imputed,\n",
    "            targets=[t],\n",
    "            parameters=v[1], cat_cols=cat_cols, int_cols=int_cols,\n",
    "            global_model_name=v[0], full_classes=classes_dict,\n",
    "            model=v[0], samplingsilo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da7f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_remove_nan_output(output,X,y,f):\n",
    "    # Get boolean array of null values\n",
    "    null_mask = np.isnan(output)\n",
    "\n",
    "    # Get the indices of the null values\n",
    "    null_indices = np.where(null_mask)\n",
    "   \n",
    "    # Get the corresponding values in arr2\n",
    "    corresponding_values = X[null_indices]\n",
    "    if null_mask.any():\n",
    "        log_to_file(f,[\"There is nan in output\"])\n",
    "        log_to_file(f,[\"nan indices\",output])\n",
    "        log_to_file(f,[\"corresponding values\",corresponding_values])\n",
    "        return np.delete(output, null_indices),np.delete(y, null_indices)\n",
    "    else:   \n",
    "        return output,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb855fb",
   "metadata": {},
   "source": [
    "# All on silos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6c06b87-391e-4be9-87f7-c33b840e78f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T15:23:42.455323Z",
     "iopub.status.busy": "2023-01-10T15:23:42.454865Z",
     "iopub.status.idle": "2023-01-10T15:23:42.481076Z",
     "shell.execute_reply": "2023-01-10T15:23:42.480702Z",
     "shell.execute_reply.started": "2023-01-10T15:23:42.455290Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_models_on_local(\n",
    "        silos, target, metrics, cv, int_cols, cat_cols, tuned_parameters, model, full_classes,f,\n",
    "        debug_mode=False\n",
    "):\n",
    "    \"\"\"\n",
    "    for every silo, trains and local model with hyperparameter tuning (CV)\n",
    "    After that, creates a global_model and with all locals and global evaluates on the test set several metrics\n",
    "    remove low frequency target (below 4) in order to get proper metric values (weighted f1 and auc)\n",
    "    \"\"\"\n",
    "    grid_list = []\n",
    "    result = {}\n",
    "    models = []\n",
    "    test_sets = []\n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d - %H:%M\")\n",
    "    f.write(date_time + \"\\n\")\n",
    "  #  print(\"starting creating locals\")\n",
    "    for idx, silo in enumerate(silos):\n",
    "        if debug_mode:\n",
    "            #print(\"silo\", str(idx))\n",
    "            print(np.random.randint(1, 20))\n",
    "        f.write(\"silo \" + str(idx) + \"\\n\")\n",
    "        if \"random_state\" in model.get_params().keys():\n",
    "            model.set_params(random_state=np.random.randint(1, 20))\n",
    "        clf = GridSearchCV(\n",
    "            model, tuned_parameters, cv=RepeatedStratifiedKFold(n_splits=cv, n_repeats=2), n_jobs=-2, scoring='f1_micro'\n",
    "        )\n",
    "        nr_classes = silo[target].unique()\n",
    "        X, y = evaluate_variables_and_transform_variables(silo, target, int_cols, cat_cols, full_classes[target])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y\n",
    "        )\n",
    "\n",
    "        test_sets.append((y_test, X_test))\n",
    "        X_train_list.append(X_train)\n",
    "        y_train_list.append(y_train)\n",
    "        models.append(clf.fit(X_train, y_train).best_estimator_)\n",
    "        #grid_list.append(clf)\n",
    "\n",
    "    distributed_model = load_model_from_zip(target + \"_\" + str(type(model).__name__) + \"_ensemble\")[\"ensemble\"]\n",
    "    centralised_model = load_model_from_zip(target + \"_\" + str(type(model).__name__) + \"_centralised\")\n",
    "   # print(\"loaded models\")\n",
    "    #print(distributed_model)\n",
    "    #print(centralised_model)\n",
    "    for idx, tests in enumerate(test_sets):\n",
    "        y_pred_l_auc = models[idx].predict_proba(tests[1])\n",
    "       # print(y_pred_l_auc)\n",
    "        y_pred_g_auc = distributed_model.predict_proba(tests[1])\n",
    "        y_pred_c_auc = centralised_model.best_estimator_.predict_proba(tests[1])\n",
    "       # print(\"here\")\n",
    "        f.write(\"silo \" + str(idx) + \"\\n\")\n",
    "        f.write(\"The sum of nan in y_pred_l_auc is:\" + str(np.sum(np.isnan(y_pred_l_auc))) + \"\\n\")\n",
    "        f.write(\"The sum of nan in y_pred_g_auc is:\" + str(np.sum(np.isnan(y_pred_g_auc))) + \"\\n\")\n",
    "        f.write(\"The sum of nan in y_pred_c_auc is:\" + str(np.sum(np.isnan(y_pred_c_auc))) + \"\\n\")\n",
    "        y_pred_l = models[idx].predict(tests[1])\n",
    "        y_pred_g = distributed_model.predict(tests[1])\n",
    "        y_pred_c = centralised_model.best_estimator_.predict(tests[1])\n",
    "\n",
    "        classes_score = centralised_model.classes_\n",
    "        f.write(str(classes_score) + \"\\n\")\n",
    "        if len(nr_classes) < 3:\n",
    "            y_pred_l_auc = y_pred_l\n",
    "            y_pred_g_auc = y_pred_g\n",
    "            y_pred_c_auc = y_pred_c\n",
    "\n",
    "        for metric in metrics:\n",
    "            if metric == \"auprc\":\n",
    "                result[\"silo\" + str(idx + 1) + \"_auprc_local\"] = auprc_multiclass(tests[0], y_pred_l_auc, classes_score)\n",
    "                result[\"silo\" + str(idx + 1) + \"_auprc_global\"] = auprc_multiclass(tests[0], y_pred_g_auc,\n",
    "                                                                                   classes_score)\n",
    "                result[\"silo\" + str(idx + 1) + \"_auprc_centralised\"] = auprc_multiclass(tests[0], y_pred_c_auc,\n",
    "                                                                                        classes_score)\n",
    "\n",
    "            if metric == \"roc_auc_score\":\n",
    "                try:\n",
    "                    result[\n",
    "                        \"silo\" + str(idx + 1) + \"_roc_auc_score_local\"\n",
    "                        ] = roc_auc_score(y_true=tests[0], y_score=y_pred_l_auc, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    f.write(\"Error on local-silo\" + \" \" + str(idx + 1) + \"\\n\")\n",
    "                    f.write(\"roc score calculate\" + \" \" + str(e) + \" ---> \"+ str(y_pred_l_auc) + \"\\n\")\n",
    "                    result[\"silo\" + str(idx + 1) + \"_roc_auc_score_local\"] = np.nan\n",
    "                try:\n",
    "                    result[\n",
    "                        \"silo\" + str(idx + 1) + \"_roc_auc_score_global\"\n",
    "                        ] = roc_auc_score(y_true=tests[0], y_score=y_pred_g_auc, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    f.write(\"Error on global-silo \" + str(idx + 1) + \"\\n\")\n",
    "                    f.write(\"roc score calculate \" + str(e) + \" ---> \" + str(y_pred_g_auc) + \"\\n\")\n",
    "                    result[\"silo\" + str(idx + 1) + \"_roc_auc_score_global\"] = np.nan\n",
    "\n",
    "                try:\n",
    "                    result[\n",
    "                        \"silo\" + str(idx + 1) + \"_roc_auc_score_centralised\"\n",
    "                        ] = roc_auc_score(y_true=tests[0], y_score=y_pred_c_auc, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    f.write(\"Error on central-silo\" + \" \" + str(idx + 1) + \"\\n\")\n",
    "                    f.write(\"roc score calculate\" + \" \" + str(e) + \" --->\" +\" \"+ str(y_pred_c_auc) + \"\\n\")\n",
    "                    result[\"silo\" + str(idx + 1) + \"_roc_auc_score_centralised\"] = np.nan\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e112354-c5cd-41e0-b3a1-9e3bf31e0631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T15:24:46.787828Z",
     "iopub.status.busy": "2023-01-10T15:24:46.786696Z",
     "iopub.status.idle": "2023-01-10T15:24:46.804835Z",
     "shell.execute_reply": "2023-01-10T15:24:46.804434Z",
     "shell.execute_reply.started": "2023-01-10T15:24:46.787787Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_all_on_local(\n",
    "        targets,\n",
    "        silos,\n",
    "        metrics,\n",
    "        tuned_parameters,\n",
    "        cv, int_cols, cat_cols, full_classes,\n",
    "        model,\n",
    "        repeats, debug_mode=False\n",
    "):\n",
    "    total = {}\n",
    "    np.random.seed(42)\n",
    "    for target in targets:\n",
    "        total[target] = {}\n",
    "        f = open(\"logs/log_\" + str(type(model).__name__) + \"_final_test_all.txt\", \"a\")\n",
    "        log_to_file(f,[\"evaluating \" , target , \"... \"])\n",
    "        for metric in metrics:\n",
    "            for silonr, silo in enumerate(silos):\n",
    "                total[target][\"silo\" + str(silonr + 1) + \"_\" + metric + \"_local\"] = []\n",
    "                total[target][\"silo\" + str(silonr + 1) + \"_\" + metric + \"_distributed\"] = []\n",
    "                total[target][\"silo\" + str(silonr + 1) + \"_\" + metric + \"_centralised\"] = []\n",
    "        #print(\"starting range repeats\")\n",
    "        for i in range(repeats):\n",
    "            log_to_file(f,[\"repeat \" , i ])\n",
    "            t = evaluate_models_on_local(\n",
    "                silos=silos,\n",
    "                target=target,\n",
    "                metrics=metrics,\n",
    "                tuned_parameters=tuned_parameters,\n",
    "                cv=cv, int_cols=int_cols, cat_cols=cat_cols,\n",
    "                model=model, full_classes=full_classes,f=f, debug_mode=debug_mode\n",
    "            )\n",
    "           # print(t)\n",
    "            for metric in metrics:\n",
    "                for silonr, silo in enumerate(silos):\n",
    "                    total[target][\n",
    "                        \"silo\" + str(silonr + 1) + \"_\" + metric + \"_local\"\n",
    "                        ].append(t[\"silo\" + str(silonr + 1) + \"_\" + metric + \"_local\"])\n",
    "\n",
    "                    total[target][\n",
    "                        \"silo\" + str(silonr + 1) + \"_\" + metric + \"_distributed\"\n",
    "                        ].append(t[\"silo\" + str(silonr + 1) + \"_\" + metric + \"_global\"])\n",
    "                    total[target][\n",
    "                        \"silo\" + str(silonr + 1) + \"_\" + metric + \"_centralised\"\n",
    "                        ].append(t[\"silo\" + str(silonr + 1) + \"_\" + metric + \"_centralised\"])\n",
    "    f.close()\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "040d72a7-27dc-432e-87e8-cac790cb1c2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-10T15:46:24.711537Z",
     "iopub.status.busy": "2023-01-10T15:46:24.709696Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tt = evaluate_all_on_local(targets=target_cat_cols,\n",
    "                           metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "                           silos=silo_imputed,\n",
    "                           cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "                           tuned_parameters = [{\"alpha\": [0.0001, 0.01,0.001], \"l1_ratio\": [0.05],\"loss\":[\"log_loss\",\"modified_huber\"]}],\n",
    "                           model=SGDClassifier(),\n",
    "                           repeats=REPS,debug_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83a1aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sgd = from_dict_to_df_raw(tt, \"SGD\")\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_sgd.to_csv(\"results/classif_all_in_all_sgd\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tt_dt = evaluate_all_on_local(targets=target_cat_cols,\n",
    "                           metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "                           silos=silo_imputed,\n",
    "                           cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "                           tuned_parameters=[{\"criterion\": [\"gini\", \"entropy\"], \"max_features\": [\"log2\", \"auto\"]}],\n",
    "                           model=DecisionTreeClassifier(),\n",
    "                           repeats=REPS,debug_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f9063",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt = from_dict_to_df_raw(tt_dt, \"decisionTree\")\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_dt.to_csv(\"results/classif_all_in_all_dt\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563253f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tt_nb = evaluate_all_on_local(targets=target_cat_cols,\n",
    "                           metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "                           silos=silo_imputed,\n",
    "                           cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "                           tuned_parameters=[{\"var_smoothing\": [1e-9, 1e-8, 1e-7]}],\n",
    "                           model=GaussianNB(),\n",
    "                           repeats=REPS,debug_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6de40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb = from_dict_to_df_raw(tt_nb, \"NaiveBayes\")\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_nb.to_csv(\"results/classif_all_in_all_nb\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ae765",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tt_ada = evaluate_all_on_local(targets=target_cat_cols,\n",
    "                           metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "                           silos=silo_imputed,\n",
    "                           cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "                           tuned_parameters={\"learning_rate\": [1, 2, 0.5], \"n_estimators\": [25, 50]},\n",
    "                           model=AdaBoostClassifier(),\n",
    "                           repeats=REPS,debug_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adaboost = from_dict_to_df_raw(tt_ada, \"ADABOOST\")\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_adaboost.to_csv(\"results/classif_all_in_all_adaboost\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb82cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "#270m\n",
    "tt_knn = evaluate_all_on_local(targets=target_cat_cols,\n",
    "                           metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "                           silos=silo_imputed,\n",
    "                           cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "                           tuned_parameters={\"n_neighbors\": [5,7,10],\"p\": [1,2]},\n",
    "                           model=KNeighborsClassifier(),\n",
    "                           repeats=REPS,debug_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9785b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = from_dict_to_df_raw(tt_knn, \"KNN\")\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_knn.to_csv(\"results/classif_all_in_all_knn\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac14510",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tt_nn = evaluate_all_on_local(targets=target_cat_cols,\n",
    "                           metrics=[\"roc_auc_score\", \"auprc\"],\n",
    "                           silos=silo_imputed,\n",
    "                           cv=CV_NUMBER, int_cols=int_cols, cat_cols=cat_cols, full_classes=classes_dict,\n",
    "                           tuned_parameters={\"solver\": [\"lbfgs\"], \"learning_rate_init\": [0.001, 1e-4], \"max_iter\": [10000, 500],\n",
    "                             \"hidden_layer_sizes\": [(100,)],\n",
    "                             \"alpha\": [1e-5, 1e-4], \"learning_rate\": [\"adaptive\"], \"tol\": [10, 20]},\n",
    "                           model=MLPClassifier(),\n",
    "                           repeats=REPS,debug_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nn = from_dict_to_df_raw(tt_nn, \"NN\")\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "df_nn.to_csv(\"results/classif_all_in_all_nn\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d5fb143",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d%H\")\n",
    "result = pd.concat([df_sgd, df_dt, df_nb, df_adaboost,df_knn,df_nn], axis=0)\n",
    "result.to_csv(\"results/classif_result_all_in_all_df_\" + date_time + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4257e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
