{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad09d5b6-e2b8-4e76-a467-e77cb944c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "from federated_eval_helper_functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.stats.api as sms\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import cm\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn import set_config\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import statistics\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer,\n",
    "    LabelBinarizer,\n",
    "    LabelEncoder,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbaae7-ae77-43a0-8516-6f3b4c841dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337b3ad6-75a0-49fa-8f55-cad675cfd5d2",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c054fd-c3da-41a0-b868-80daa8e94a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "266b169b-120f-4db7-836d-e920d2c4862e",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28192c7-5bf2-4716-844b-c498b70b4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "silos = []\n",
    "for i in range(9):\n",
    "    silos.append(eval(\"silo\" + str(i + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e09732-0485-4061-a033-bac43232551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = [\n",
    "    \"IDADE_MATERNA\",\n",
    "    \"PESO_INICIAL\",\n",
    "    \"IMC\",\n",
    "    \"NUMERO_CONSULTAS_PRE_NATAL\",\n",
    "    \"IDADE_GESTACIONAL_ADMISSAO\",\n",
    "    \"SEMANAS_GESTACAO_PARTO\",\n",
    "    \"PESO_ADMISSAO_INTERNAMENTO\"\n",
    "\n",
    "\n",
    "]\n",
    "%store int_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527f1c5-153b-4b3b-8c93-750fce98ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    \"IDENTIFICADOR\",\n",
    "    \"G_TERAPEUTICA\",\n",
    "    \"DATA_PARTO\",\n",
    "    \"CESARIANAS_MOTIVO_ANTERIOR\",\n",
    "    \"NUM_RN\",\n",
    "    \"E_ALT_UT\",\n",
    "      'HIPERTENSAO_CRONICA',\n",
    "         'HIPERTENSAO_GESTACIONAL',\n",
    "         'HIPERTENSAO_PRE_ECLAMPSIA',\n",
    "         'DIABETES_GESTACIONAL_DIETA',\n",
    "         'DIABETES_GESTACIONAL_INSULINA',\n",
    "         'DIABETES_GESTACIONAL_ANTIBIO',\n",
    "         'DIABETES_MATERNA',\n",
    "         'DIABETES_TIPO1',\n",
    "         'DIABETES_TIPO2',\n",
    "         'HEMATOLOGICA',\n",
    "         'RESPIRATORIA',\n",
    "         'CEREBRAL',\n",
    "         'CARDIACA',\n",
    "    \"ESTIMATIVA_PESO_ECO_24\",\n",
    "    \"ESTIMATIVA_PESO_ECO_25\",\n",
    "    \"ESTIMATIVA_PESO_ECO_26\",\n",
    "    \"ESTIMATIVA_PESO_ECO_27\",\n",
    "    \"ESTIMATIVA_PESO_ECO_28\",\n",
    "    \"ESTIMATIVA_PESO_ECO_29\",\n",
    "    \"ESTIMATIVA_PESO_ECO_30\",\n",
    "    \"ESTIMATIVA_PESO_ECO_31\",\n",
    "    \"ESTIMATIVA_PESO_ECO_32\",\n",
    "    \"ESTIMATIVA_PESO_ECO_33\",\n",
    "    \"ESTIMATIVA_PESO_ECO_34\",\n",
    "    \"ESTIMATIVA_PESO_ECO_35\",\n",
    "    \"ESTIMATIVA_PESO_ECO_36\",\n",
    "    \"ESTIMATIVA_PESO_ECO_37\",\n",
    "    \"ESTIMATIVA_PESO_ECO_38\",\n",
    "    \"ESTIMATIVA_PESO_ECO_39\",\n",
    "    \"ESTIMATIVA_PESO_ECO_40\",\n",
    "    \"ESTIMATIVA_PESO_ECO_41\",\n",
    "    \"ESTIMATIVA_PESO_ECO_42\",\n",
    "    \"APRESENTACAO_24\",\n",
    "    \"APRESENTACAO_25\",\n",
    "    \"APRESENTACAO_26\",\n",
    "    \"APRESENTACAO_27\",\n",
    "    \"APRESENTACAO_28\",\n",
    "    \"APRESENTACAO_29\",\n",
    "    \"APRESENTACAO_30\",\n",
    "    \"APRESENTACAO_31\",\n",
    "    \"APRESENTACAO_32\",\n",
    "    \"APRESENTACAO_33\",\n",
    "    \"APRESENTACAO_34\",\n",
    "    \"APRESENTACAO_35\",\n",
    "    \"APRESENTACAO_36\",\n",
    "    \"APRESENTACAO_37\",\n",
    "    \"APRESENTACAO_38\",\n",
    "    \"APRESENTACAO_39\",\n",
    "    \"APRESENTACAO_40\",\n",
    "    \"APRESENTACAO_41\",\n",
    "    \"APRESENTACAO_42\",\n",
    "\"ALCOOL\",\n",
    "\"ESTUPEFACIENTES\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c826f-87ae-4538-80e9-960364bbcf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = list(set(silos[0].columns) - set(drop_cols) - set(int_cols))\n",
    "%store cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7650beaf-e210-4025-a52a-b6f543479e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "silos_null=[]\n",
    "for silo in silos:\n",
    "    \n",
    "    silos_null.extend(silo.columns[silo.isna().all()].tolist())\n",
    "Counter(silos_null) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac07a01-2cff-4880-bc38-e3c5f075ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_null=[]\n",
    "for silo in silos:\n",
    "         for col in silo.columns:\n",
    "            if sum(silo[col].isna())/len(silo)>0.9:\n",
    "                high_null.append(col)\n",
    "for k,v in Counter(high_null).items():\n",
    "    if v>8:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c4406-992f-4b9a-9510-5d473f4dea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_with_y(\n",
    "    data,\n",
    "    target,\n",
    "    int_cols,\n",
    "    cat_cols,\n",
    "    manual_encoder,\n",
    "    drop_cols=None,\n",
    "    pipeline=None,\n",
    "    op=\"encoder\",\n",
    "    as_df=False,\n",
    "):\n",
    "    _cat_cols = [colc for colc in cat_cols if colc not in [target]]\n",
    "    _int_cols = [coli for coli in int_cols if coli not in [target]]\n",
    "    n_df = data.copy().drop(columns=drop_cols + [target])\n",
    "\n",
    "    def mapping_enc(x,encoder):\n",
    "        #print(x,encoder)\n",
    "        return encoder[x]\n",
    "    \n",
    "    vfunc = np.vectorize(mapping_enc)\n",
    "\n",
    "    def manual_ordinal_encoder(x):\n",
    "        for idx,c in enumerate(_cat_cols):\n",
    "         #   print(manual_encoder[c])\n",
    "            print(c)\n",
    "            x[:,idx]=vfunc(x[:,idx],manual_encoder[c])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def to_object(x):\n",
    "        return pd.DataFrame(x).astype(str)\n",
    "\n",
    "    def to_number(x):\n",
    "        return pd.DataFrame(x).astype(float)\n",
    "\n",
    "    if pipeline == None:\n",
    "        fun_str = FunctionTransformer(to_object)\n",
    "        fun_num = FunctionTransformer(to_number)\n",
    "        unified_ordinal_enconder = FunctionTransformer(manual_ordinal_encoder)\n",
    "\n",
    "        numeric_transformer = Pipeline(\n",
    "            steps=[                (\"fun_num\", fun_num),\n",
    "                (\"imputer1\", SimpleImputer(strategy=\"median\", missing_values=np.nan)),\n",
    "                (\"imputer2\", SimpleImputer(strategy=\"median\", missing_values=-1)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        categorical_transformer = Pipeline(\n",
    "            steps=[\n",
    "             #   (\"fun_str\", fun_str),\n",
    "                (\n",
    "                    \"imputer\",\n",
    "                    SimpleImputer(\n",
    "                        missing_values=np.nan, strategy=\"constant\", fill_value=\"NULLIMP\"\n",
    "                    ),\n",
    "                ),\n",
    "                (\"ordinalEncoder\", unified_ordinal_enconder),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", numeric_transformer, _int_cols),\n",
    "                (\"cat\", categorical_transformer, _cat_cols),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor)])\n",
    "\n",
    "        y = data[target]\n",
    "        X = n_df\n",
    "        y_pipe = make_pipeline(\n",
    "            SimpleImputer(\n",
    "                missing_values=np.nan, strategy=\"constant\", fill_value=\"NULLIMP\"\n",
    "            )\n",
    "        )\n",
    "        yy, l = create_target(y, op=op)\n",
    "        XX = pipeline.fit_transform(X)\n",
    "\n",
    "        if as_df == True:\n",
    "            col_list = (\n",
    "                pipeline[\"preprocessor\"].transformers_[0][2] #changes col location\n",
    "                + pipeline[\"preprocessor\"].transformers_[1][2]\n",
    "            )\n",
    "            print(len(col_list))\n",
    "            df1 = pd.DataFrame(XX, columns=col_list)\n",
    "            r = pd.concat([df1, pd.DataFrame(yy)], axis=1)\n",
    "            r.rename(columns={0: target}, inplace=True)\n",
    "            return r, None, pipeline, l\n",
    "        return XX, yy, pipeline, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a080c448-310f-4ca4-89e6-ccd5956ed2a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing_df(\n",
    "    df,\n",
    "    categorical_columns,\n",
    "    integ_columns,\n",
    "    drop_cols=[\"G_TERAPEUTICA\", \"IDENTIFICADOR\"],\n",
    "    pipeline=[\"imputer\", \"encoder\"],\n",
    "):\n",
    "    if len(df.columns) != len(categorical_columns) + len(integ_columns) + len(drop_cols):\n",
    "        # raise Exception\n",
    "        raise(\"WARNING! Columns number different\")\n",
    "    df1 = df.copy()\n",
    "\n",
    "    def simple_imputer_categorical_df(df, columns):\n",
    "        imputer = SimpleImputer(\n",
    "            missing_values=np.nan, strategy=\"constant\", fill_value=\"NULLIMP\"\n",
    "        )  # está a por NULL em variaveis com nrs(apesar de considerar cat)\n",
    "        imputer.fit(df[columns])\n",
    "        X = pd.DataFrame(imputer.transform(df[columns]))\n",
    "        return X\n",
    "\n",
    "    def simple_imputer_numeric_df(df, columns):\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy=\"median\")\n",
    "        imputer.fit(df[columns].astype(float))\n",
    "        X = pd.DataFrame(imputer.transform(df[columns]))\n",
    "        return X\n",
    "\n",
    "    def scikit_one_hot_encoder(df, categorical_columns):\n",
    "        enc_hot = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "        enc_hot.fit(df[categorical_columns].astype(str))\n",
    "        X = pd.DataFrame(\n",
    "            enc_hot.transform(df[categorical_columns].astype(str)),\n",
    "            columns=enc_hot.get_feature_names(df[categorical_columns].columns),\n",
    "        )\n",
    "        data_encoded = pd.concat([df, X], axis=1)\n",
    "        data_encoded.drop(columns=df[categorical_columns].columns, inplace=True)\n",
    "        return data_encoded\n",
    "\n",
    "    df1.drop(columns=drop_cols, inplace=True)\n",
    "    if \"imputer\" in pipeline:\n",
    "        df1[categorical_columns] = simple_imputer_categorical_df(\n",
    "            df1, categorical_columns\n",
    "        )\n",
    "        df1[integ_columns] = simple_imputer_numeric_df(df1, integ_columns)\n",
    "\n",
    "    if \"encoder\" in pipeline:\n",
    "        df1 = scikit_one_hot_encoder(df1, categorical_columns)\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f32c2-aebc-489f-b345-6c31b0bf0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform all from SIM/NAO to S/N and similar\n",
    "unique_values={}\n",
    "standard_map={\"ADEQUADA\":\"A\",\"LIMITE\":\"L\",\"DESCONHECIDO,RH_DESCONHECIDO\":np.nan,\"DESCONHECIDO,\":np.nan,\"SIM\":\"S\",\"NAO\":\"N\",\"-1\":np.nan,-1:np.nan,\"NS\":np.nan,\",\":np.nan,\"Sim\":\"S\",\"UNKNOWN\":np.nan,\"Desconhecida\":np.nan,\"Desconhecido\":np.nan,\"DESCONHECIDO\":np.nan,\" \":np.nan,\"Desconhecido,\":np.nan,\"  \":np.nan}\n",
    "def standardize_null(x,mapping):\n",
    "    if x in mapping.keys():\n",
    "        return mapping[x]\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    return x\n",
    "for silo in silos:\n",
    "    for col in silo.columns:\n",
    "        silo[col]=silo[col].apply(standardize_null,mapping=standard_map)\n",
    "        \n",
    "    for col in silo.columns:\n",
    "        if col in cat_cols:\n",
    "            if col in unique_values.keys():\n",
    "                unique_values[col].extend(silo[col].unique())\n",
    "            else:\n",
    "                unique_values[col]=list(silo[col].unique())\n",
    "for k,v in unique_values.items():\n",
    "    unique_values[k]=[\"NULLIMP\" if  pd.isnull(x) else x for x in unique_values[k]]\n",
    "    unique_values[k]=set(unique_values[k])\n",
    "manual_encoder={}\n",
    "for k,v in unique_values.items():\n",
    "    n=len(v)\n",
    "    manual_encoder[k]=dict(zip(v,[str(x) for x in (range(0,n))]))\n",
    "manual_encoder\n",
    "#with open('manual_encoder.json', 'w') as outfile:\n",
    "# write\n",
    "with open('manual_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(manual_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f9e9f-e6da-4fbf-bc0e-f3a2f6916915",
   "metadata": {},
   "outputs": [],
   "source": [
    "silosprep = []\n",
    "silo_imputed = []\n",
    "silos_stats = []\n",
    "for silo in silos:\n",
    "    \n",
    "    silos_stats.append(silo.copy())\n",
    "    silosprep.append(\n",
    "        preprocessing_df(\n",
    "            silo,\n",
    "            categorical_columns=cat_cols,\n",
    "            integ_columns=int_cols,\n",
    "            drop_cols=drop_cols,\n",
    "        )\n",
    "    )\n",
    "    silo_imputed.append(\n",
    "        create_pipeline_with_y(\n",
    "            silo.copy(),\n",
    "            \"GRUPO_ROBSON\",\n",
    "            int_cols=int_cols,\n",
    "            unique_values=unique_values,\n",
    "            cat_cols=cat_cols,\n",
    "            as_df=True,\n",
    "            drop_cols=drop_cols, \n",
    "        )[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c9183-4323-4885-b5d3-6a05b0e22444",
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_list = []\n",
    "for silo in silosprep:\n",
    "    resulting_list.extend(x for x in silo.columns.tolist() if x not in resulting_list)\n",
    "for col in resulting_list:\n",
    "    for i in range(len(silosprep)):\n",
    "        if col not in silosprep[i].columns:\n",
    "            silosprep[i][col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0728ca-8c80-4e87-93cd-eafe4cc32e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter()\n",
    "final_list = []\n",
    "for s in silos_stats:\n",
    "    c.update(s.columns)\n",
    "for col in c.keys():\n",
    "    if c[col] == 9:\n",
    "        final_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73312acf-c73c-4b2b-929a-571c90d749ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in final_list:\n",
    "    for i in range(len(silos_stats)):\n",
    "        #  print(silos_stats[i].columns)\n",
    "        if col not in silos_stats[i].columns:\n",
    "            silos_stats[i][col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d150ec79-3ddd-425e-8ac8-1fde5d084445",
   "metadata": {},
   "outputs": [],
   "source": [
    "for silo in silos_stats:\n",
    "    print(len(silo.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
